# ğŸš€ LLM Evaluation Suite - Production Deployment

**Status**: âœ… Production Ready  
**Version**: 1.0.0  
**Deployed**: October 17, 2025

---

## ğŸ¯ Quick Deployment Guide

### Installation

```bash
git clone https://github.com/kalpeshjaju/llm-evaluation-suite.git
cd llm-evaluation-suite
npm install
cp .env.example .env
# Add your ANTHROPIC_API_KEY to .env
```

### Run First Evaluation

```bash
# Example evaluation
npm run test:example

# View results
npm run view
```

---

## ğŸ†“ Two Modes

### FREE Mode (Claude Code)
```bash
npm run eval:prompt my-project
# Copy output to Claude Code for FREE evaluation
```

### API Mode ($0.003/eval)
```bash
npm run eval:all
# Automated batch evaluations
```

---

## ğŸ“Š Key Features

- âœ… Claude-as-Judge evaluation
- âœ… PromptFoo integration
- âœ… CI/CD ready (GitHub Actions)
- âœ… Cost tracking
- âœ… Quality gates
- âœ… Comprehensive documentation

---

## ğŸ’° Costs

- **FREE Mode**: $0/month (Claude Pro subscription)
- **API Mode**: ~$0.003-0.01 per evaluation
- **Typical Usage**: $5-20/month for 1000-2000 evaluations

---

## ğŸ“ Documentation

- [README.md](./README.md) - Complete usage guide
- [QUICKSTART.md](./QUICKSTART.md) - 2-minute setup
- [EVALUATION_GUIDE.md](./EVALUATION_GUIDE.md) - Evaluation patterns
- [CI-CD-GUIDE.md](./CI-CD-GUIDE.md) - Integration examples
- [CLAUDE.md](./CLAUDE.md) - Developer documentation

---

## âœ… Production Ready Checklist

- [x] PromptFoo integration working
- [x] Claude-as-Judge tested
- [x] Example configurations included
- [x] CI/CD guides available
- [x] Comprehensive documentation
- [x] GitHub repository active
- [x] All dependencies updated

---

## ğŸš€ Next Steps

1. Install and configure
2. Run example evaluation
3. Integrate into your workflow
4. Setup CI/CD (optional)
5. Monitor quality metrics

**Setup Time**: 5-15 minutes  
**Time to Value**: <2 minutes

---

For detailed deployment instructions, see README.md and other documentation files.
