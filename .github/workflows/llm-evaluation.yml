# GitHub Actions: LLM Evaluation Suite
# Runs automated quality checks on every push and PR

name: LLM Quality Check

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]
  workflow_dispatch:  # Allow manual trigger

jobs:
  evaluate:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run LLM evaluation
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          CLAUDE_MODEL: claude-sonnet-4-20250514
        run: |
          echo "ü§ñ Running LLM evaluation suite..."
          npm run eval
        continue-on-error: false

      - name: Check evaluation results
        run: |
          if [ -f test-results.json ]; then
            echo "‚úÖ Evaluation completed"
            echo "üìä Results summary:"
            node scripts/check-results.js
          else
            echo "‚ùå No results file found"
            exit 1
          fi

      - name: Upload evaluation results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-results
          path: |
            test-results.json
            .promptfoo/
          retention-days: 30

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            if (fs.existsSync('test-results.json')) {
              const results = JSON.parse(fs.readFileSync('test-results.json', 'utf8'));

              // Generate summary
              const passed = results.results?.filter(r => r.success).length || 0;
              const total = results.results?.length || 0;
              const passRate = total > 0 ? Math.round((passed / total) * 100) : 0;

              const comment = `## ü§ñ LLM Evaluation Results

              **Pass Rate**: ${passRate}% (${passed}/${total} tests passed)

              ${passRate >= 70 ? '‚úÖ Quality check passed!' : '‚ùå Quality check failed - improvements needed'}

              <details>
              <summary>View detailed results</summary>

              \`\`\`json
              ${JSON.stringify(results, null, 2).slice(0, 2000)}
              \`\`\`

              </details>

              üìä [View full results in artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
              `;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

      - name: Fail if quality threshold not met
        run: |
          node scripts/enforce-quality.js
        env:
          MIN_PASS_RATE: 70  # Require 70% pass rate

  cost-estimate:
    runs-on: ubuntu-latest
    needs: evaluate
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Estimate API costs
        run: |
          echo "üí∞ Estimating API costs..."
          if [ -f test-results.json ]; then
            node scripts/estimate-cost.js
          else
            echo "No results to analyze"
          fi
